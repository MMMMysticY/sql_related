{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SparkSQL学习\n",
    "SparkSQL通过调用SQL语句或DataFrame相关API描述操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "spark_home = 'D:\\spark3.0.1\\spark-3.0.1-bin-hadoop3.2'\n",
    "python_path = 'D:\\Python3\\python.exe'\n",
    "\n",
    "findspark.init(spark_home, python_path)\n",
    "# 配置spark和python的路径"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#SparkSQL的大部分功能封装在SparkSession的方法接口中\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"test\") \\\n",
    "        .config(\"master\",\"local[4]\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataFrame\n",
    "DataFrame借鉴了pandas的思想，能够按照列进行获取信息；而在RDD部分学习过程时，所有的行为都是List化的，对每个对象进行处理/过滤等任务，是按行处理数据的逻辑。\n",
    "是不是可以说，DataFrame中有多列属性，类似于多PairRDD，对PairRDD更结构化得处理。\n",
    "DataFrame相较于RDD加入了schema(模式)的概念，**schema是描述数据结构和字段类型的元数据信息，它用来定义每个列的名称、数据类型和其他属性**。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataFrame构建\n",
    "1. 从RDD构建(toDF)；\n",
    "2. 从pandas的DataFrame对象构建(createDataFrame)\n",
    "3. 从list对象直接创建(createDataFrame)\n",
    "4. 显式设定schema和rdd细节构建(createDataFrame)\n",
    "5. 从文件创建(json文件、csv文件、hive表数据、mysql表数据)\n",
    "\n",
    "前四种方法都是小规模数据测试使用，主流方法应为从文件创建"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"LiLei\",15,88),(\"HanMeiMei\",16,90),(\"DaChui\",17,60)])\n",
    "# 构建一个普通的RDD，RDD本质上还是按行来处理的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = rdd.toDF(['name', 'age', 'score'])\n",
    "# 定义schema中的名称选项，即可从RDD构建DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-----+\n",
      "|     name|age|score|\n",
      "+---------+---+-----+\n",
      "|    LiLei| 15|   88|\n",
      "|HanMeiMei| 16|   90|\n",
      "|   DaChui| 17|   60|\n",
      "+---------+---+-----+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()\n",
    "# schema中包括了名称、数据类型和额外属性"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = pd.DataFrame([(\"LiLei\",18),(\"HanMeiMei\",17)],columns = [\"name\",\"age\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|    LiLei| 18|\n",
      "|HanMeiMei| 17|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从pandas对象构建\n",
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|    LiLei| 18|\n",
      "|HanMeiMei| 17|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values = [(\"LiLei\",18),(\"HanMeiMei\",17)]\n",
    "df = spark.createDataFrame(values,[\"name\",\"age\"])\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, DateType, StructType, StructField\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"name\", StringType(), nullable=False),\n",
    "        StructField(\"score\", IntegerType(), nullable=True),\n",
    "        StructField(\"birthday\", DateType(), nullable=True)\n",
    "     ]\n",
    ")\n",
    "# 设定schema为Struct类型，每个字段都设定名称、类型和是否可为空"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(\n",
    "    [   Row(\"LiLei\",87,datetime(2010,1,5)),\n",
    "        Row(\"HanMeiMei\",90,datetime(2009,3,1)),\n",
    "        Row(\"DaChui\",None,datetime(2008,7,2))\n",
    "     ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+\n",
      "|     name|score|  birthday|\n",
      "+---------+-----+----------+\n",
      "|    LiLei|   87|2010-01-05|\n",
      "|HanMeiMei|   90|2009-03-01|\n",
      "|   DaChui| null|2008-07-02|\n",
      "+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfstudent = spark.createDataFrame(rdd, schema)\n",
    "dfstudent.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 通过文件创建"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|    LiLei| 18|\n",
      "|HanMeiMei| 17|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_json = spark.read.json('data/people.json')\n",
    "df.show()\n",
    "# 读取json文件"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|label|\n",
      "+-----------+----------+-----------+----------+-----+\n",
      "|        5.1|       3.5|        1.4|       0.2|    0|\n",
      "|        4.9|       3.0|        1.4|       0.2|    0|\n",
      "|        4.7|       3.2|        1.3|       0.2|    0|\n",
      "|        4.6|       3.1|        1.5|       0.2|    0|\n",
      "|        5.0|       3.6|        1.4|       0.2|    0|\n",
      "+-----------+----------+-----------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- sepallength: double (nullable = true)\n",
      " |-- sepalwidth: double (nullable = true)\n",
      " |-- petallength: double (nullable = true)\n",
      " |-- petalwidth: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"inferSchema\", 'true') \\\n",
    "    .csv('data/iris.csv')\n",
    "\n",
    "df_csv.show(5)\n",
    "df_csv.printSchema()\n",
    "\n",
    "# 从csv文件读取 要设置表头、分隔符等"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------------+\n",
      "|  name|favorite_color|favorite_numbers|\n",
      "+------+--------------+----------------+\n",
      "|Alyssa|          null|  [3, 9, 15, 20]|\n",
      "|   Ben|           red|              []|\n",
      "+------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet = spark.read.parquet('data/users.parquet')\n",
    "df_parquet.show()\n",
    "# 直接从parquet文件读取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataFrame存储\n",
    "1. 保存为csv\n",
    "2. 转为rdd后再保存为txt\n",
    "3. 保存为json\n",
    "4. 保存成parquet文件\n",
    "5. 保存入数据库"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|label|\n",
      "+-----------+----------+-----------+----------+-----+\n",
      "|        5.1|       3.5|        1.4|       0.2|    0|\n",
      "|        4.9|       3.0|        1.4|       0.2|    0|\n",
      "|        4.7|       3.2|        1.3|       0.2|    0|\n",
      "|        4.6|       3.1|        1.5|       0.2|    0|\n",
      "|        5.0|       3.6|        1.4|       0.2|    0|\n",
      "+-----------+----------+-----------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- sepallength: double (nullable = true)\n",
      " |-- sepalwidth: double (nullable = true)\n",
      " |-- petallength: double (nullable = true)\n",
      " |-- petalwidth: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.show(5)\n",
    "df_csv.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 直接以csv形式存储\n",
    "df_csv.write.format('csv').option(\"header\", 'true').save('./data/iris_write.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 转为rdd再保存为txt文件\n",
    "df_csv.rdd.saveAsTextFile('/data/iris_write.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 以json形式存储\n",
    "df_csv.write.json('./data/iris_write.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存成parquet文件 压缩格式，占用存储小，且为spark内存中的存储形式，加载最快\n",
    "df_csv.write.partitionBy('label').format(\"parquet\").save('data/iris_write.parquet')\n",
    "# 或者\n",
    "df_csv.write.parquet('data/iris_write.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataFrame的API操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, Column\n",
    "import pyspark.sql.functions as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "+---------+---+------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"LiLei\",15,\"male\"),\n",
    "     (\"HanMeiMei\",16,\"female\"),\n",
    "     (\"DaChui\",17,\"male\")\n",
    "     ]\n",
    ").toDF(\"name\", 'age', 'gender')\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Action操作\n",
    "Action类操作主要是对信息的展现，包括show、count、collect、describe、take、head、first等"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "+---------+---+------+\n",
      "\n",
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "+---------+---+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show(numRows, truncate:Boolean)方法\n",
    "df.show()\n",
    "# 全显式\n",
    "df.show(2, truncate=True)\n",
    "# 仅显示两行"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count() 返回DataFrame的行数\n",
    "df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(name='LiLei', age=15, gender='male'),\n Row(name='HanMeiMei', age=16, gender='female'),\n Row(name='DaChui', age=17, gender='male')]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect() 应该类似于RDD中的collect 将数据整合展示\n",
    "df.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(name='LiLei', age=15, gender='male'),\n Row(name='HanMeiMei', age=16, gender='female')]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 最上面一行  take(n) 显示前面n个 head(n) 显示顶部n个\n",
    "df.first()\n",
    "df.take(2)\n",
    "df.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 类RDD操作\n",
    "DataFrame支持RDD中的一些诸如distinct、cache、sample、foreach、intersect、except等操作。\n",
    "**可以把DataFrame当做数据类型为Row的RDD**\n",
    "这类方法似乎有些鸡肋"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[<Row('LiLei', 15, 'MALE')>,\n <Row('HanMeiMei', 16, 'FEMALE')>,\n <Row('DaChui', 17, 'MALE')>]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map方法 先转换为RDD\n",
    "rdd = df.rdd.map(lambda x:Row(x[0], x[1], x[2].upper()))\n",
    "rdd.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------------+\n",
      "|     name|age|upper_gender|\n",
      "+---------+---+------------+\n",
      "|    LiLei| 15|        MALE|\n",
      "|HanMeiMei| 16|      FEMALE|\n",
      "|   DaChui| 17|        MALE|\n",
      "+---------+---+------------+\n",
      "\n",
      "+---------+---+------------+\n",
      "|     name|age|upper_gender|\n",
      "+---------+---+------------+\n",
      "|    LiLei| 15|        MALE|\n",
      "|HanMeiMei| 16|      FEMALE|\n",
      "|   DaChui| 17|        MALE|\n",
      "+---------+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd.toDF([\"name\", 'age', 'upper_gender']).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 过滤filter功能 也要转为RDD\n",
    "df_filtered = df.rdd.filter(lambda x:x[1]>=16).toDF(['name', 'age', 'gender'])\n",
    "df_filtered.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|   DaChui| 17|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|    LiLei| 15|  male|\n",
      "|   DaChui| 18|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distinct功能 不用转为RDD 直接可以去重\n",
    "# 行中每一列均相同才会去重\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [(\"LiLei\",15,\"male\"),\n",
    "     (\"HanMeiMei\",16,\"female\"),\n",
    "     (\"DaChui\",17,\"male\"),\n",
    "     (\"LiLei\",15,\"male\"),\n",
    "     (\"DaChui\",18,\"male\")\n",
    "     ]\n",
    ").toDF(\"name\", 'age', 'gender')\n",
    "\n",
    "df.distinct().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"LiLei\",15,\"male\"),\n",
    "     (\"HanMeiMei\",16,\"female\"),\n",
    "     (\"DaChui\",17,\"male\"),\n",
    "     ]\n",
    ").toDF(\"name\", 'age', 'gender')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|HanMeiMei| 16|female|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 采样功能\n",
    "df_sample = df.sample(0.1,0)\n",
    "\n",
    "df_sample.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# 两个DataFrame的集合运算\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [(\"Xiaoming\",80,\"male\"),\n",
    "     (\"Xiaohong\",81,\"female\"),\n",
    "     (\"Xiaozhang\",82,\"male\"),\n",
    "     ]\n",
    ").toDF(\"name\", \"score\", \"gender\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 当两个DataFrame的schema有多列时 似乎不能进行集合运算\n",
    "\n",
    "df_intersect = df.intersect(df2)\n",
    "df_intersect.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame(\n",
    "    [(\"Xiaoming\",80,\"male\"),\n",
    "     (\"Xiaohong\",81,\"female\"),\n",
    "     (\"Xiaozhang\",82,\"male\"),\n",
    "     ]\n",
    ").toDF(\"name\", \"age\", \"gender\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_intersect = df.intersect(df3)\n",
    "df_intersect.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 类Pandas操作\n",
    "1. 广播操作\n",
    "2. 增加/删除/重命名列(withColumn, drop, withColumnRenamed)\n",
    "3. 排序(sort orderBy)\n",
    "4. 异常值处理(na.drop na.fill na.replace)\n",
    "5. 过滤处理 (replace替换、dropDuplicate去重\n",
    "6. 简单函数 agg聚合操作 describe汇总信息"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "|    RuHua| 16|  null|\n",
      "+---------+---+------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "(\"LiLei\",15,\"male\"),\n",
    "(\"HanMeiMei\",16,\"female\"),\n",
    "(\"DaChui\",17,\"male\"),\n",
    "(\"RuHua\",16,None)\n",
    "]).toDF(\"name\",\"age\",\"gender\")\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+--------+\n",
      "|     name|age|gender|birthday|\n",
      "+---------+---+------+--------+\n",
      "|    LiLei| 15|  male|    2005|\n",
      "|HanMeiMei| 16|female|    2004|\n",
      "|   DaChui| 17|  male|    2003|\n",
      "|    RuHua| 16|  null|    2004|\n",
      "+---------+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 广播操作 和 增加列 withColumn操作\n",
    "\n",
    "df_new = df.withColumn('birthday', 2020-df['age'])\n",
    "# 和pandas一样对列名的操作是广播出去的 即维度为(1,)的对象与维度为(Row_num, 1)的对象的运算\n",
    "\n",
    "df_new.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|     name|age|\n",
      "+---------+---+\n",
      "|    LiLei| 15|\n",
      "|HanMeiMei| 16|\n",
      "|   DaChui| 17|\n",
      "|    RuHua| 16|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 删除列 drop\n",
    "df_dropped = df.drop(\"gender\")\n",
    "df_dropped.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|   sex|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "|    RuHua| 16|  null|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 重命名列\n",
    "df_renamed = df.withColumnRenamed('gender', 'sex')\n",
    "df_renamed.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n",
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|   DaChui| 17|  male|\n",
      "|    RuHua| 16|  null|\n",
      "|HanMeiMei| 16|female|\n",
      "|    LiLei| 15|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 排序 sort(排序规则)\n",
    "sort_rule = df['age'].desc()\n",
    "print(type(sort_rule))\n",
    "# 生成的column对象 作为排序方式\n",
    "\n",
    "df_sorted = df.sort(sort_rule)\n",
    "df_sorted.show()\n",
    "# sort方法调用排序方式"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|    RuHua| 16|  null|\n",
      "|   DaChui| 17|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 也可以直接按照某列名或多个列进行排序\n",
    "df.sort('age').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|   DaChui| 17|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|    RuHua| 16|  null|\n",
      "|    LiLei| 15|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orderby方法可以按照多个字段进行排序\n",
    "df_ordered = df.orderBy(df['age'].desc(), df['name'].asc())\n",
    "df_ordered.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop去掉空值\n",
    "df_not_na = df.na.drop()\n",
    "df_not_na.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "|    RuHua| 16|female|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# na.fill 填充空值\n",
    "df_fill = df.na.fill(\"female\")\n",
    "df_fill.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "|     SiYu| 16|  null|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace方法可以直接替换\n",
    "df_replaced2 = df.replace({\"\":\"female\", \"RuHua\":\"SiYu\"})\n",
    "df_replaced2.show()\n",
    "# 空值没替换成功"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "|    RuHua| 16|  null|\n",
      "|    LiLei| 15|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|   DaChui| 17|  male|\n",
      "|    RuHua| 16|  null|\n",
      "+---------+---+------+\n",
      "\n",
      "+---------+---+------+\n",
      "|     name|age|gender|\n",
      "+---------+---+------+\n",
      "|    RuHua| 16|  null|\n",
      "|   DaChui| 17|  male|\n",
      "|HanMeiMei| 16|female|\n",
      "|    LiLei| 15|  male|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.unionAll(df)\n",
    "df2.show()\n",
    "# 使用unionAll进行连接 由于是unionAll所以不会自动去重\n",
    "\n",
    "df_unique = df.dropDuplicates()\n",
    "df_unique.show()\n",
    "# dropDuplicates进行去重"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|count(name)|max(age)|\n",
      "+-----------+--------+\n",
      "|          4|      17|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 简单聚合操作agg: 使用简单的名称描述方法\n",
    "df_agg = df.agg({\"name\": \"count\", \"age\":\"max\"})\n",
    "df_agg.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+------+\n",
      "|summary|  name|              age|gender|\n",
      "+-------+------+-----------------+------+\n",
      "|  count|     4|                4|     3|\n",
      "|   mean|  null|             16.0|  null|\n",
      "| stddev|  null|0.816496580927726|  null|\n",
      "|    min|DaChui|               15|female|\n",
      "|    max| RuHua|               17|  male|\n",
      "+-------+------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 经典的describe方法获得表细节\n",
    "\n",
    "df_desc = df.describe()\n",
    "df_desc.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 类SQL表操作 ☆\n",
    "类SQL操作是最常用且与SQL表最为密切的处理方式\n",
    "将DataFrame看做数据库表，或者本身就是从数据库读取出的数据构建的DataFrame。\n",
    "这样用pyspark可以执行SQL类任务。  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}